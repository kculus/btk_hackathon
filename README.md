# ğŸ§  Chatbot sistemi â€“ `neuralwork/gemma-2-9b-it-tr` + QLoRA + RAG

Bu proje, **Hugging Face'teki `neuralwork/gemma-2-9b-it-tr`** modelini baz alÄ±r. TÃ¼rkÃ§e iÃ§eriklere Ã¶zel LoRA tabanlÄ± fine-tuning ve Retrievalâ€‘Augmented Generation (RAG) ile belge destekli sohbet sistemi geliÅŸtirilmiÅŸtir.

---

## ğŸ§ª Temel Model: `neuralwork/gemma-2-9b-it-tr`

- `google/gemma-2-9b-it` Ã¼zerine **yaklaÅŸÄ±k 55k soru-cevap ve konuÅŸma Ã¶rneÄŸi ile fine-tune edilmiÅŸ** bir modeldir :contentReference[oaicite:1]{index=1}.
- LoRA parametreleri: `rank=128`, `lora_alpha=64`; eÄŸitim sÃ¼resi ~4 gÃ¼n, RTX 6000 Ada GPU kullanÄ±lmÄ±ÅŸtÄ±r :contentReference[oaicite:2]{index=2}.
- Model, TÃ¼rkÃ§e'de daha iyi konuÅŸma ve mantÄ±ksal Ã§Ã¶zÃ¼mleme yeteneklerine sahiptir.

- Bu model LoRa ile fine tune edildi ve konu anlatÄ±mÄ± yapabilen chatbot oluÅŸturuldu. Bu aÅŸamada kullanÄ±lan veri seti ve oluÅŸan modelin linki aÅŸaÄŸÄ±da yer almaktadÄ±r.
- Model linki: https://huggingface.co/yagiz1323/EducationalChatbot/tree/main
- Model iÃ§in kullanÄ±lan veri seti: https://huggingface.co/datasets/yagiz1323/FinetuningTurkishMat/tree/main

---
# ğŸ§  Advanced RAG Sistemi - DetaylÄ± AÃ§Ä±klama

Bu proje, **TÃ¼rkÃ§e matematik eÄŸitimi** iÃ§in geliÅŸtirilmiÅŸ geliÅŸmiÅŸ bir **Retrieval-Augmented Generation (RAG)** sistemi kullanmaktadÄ±r. Sistem, Ã¶ÄŸrencilerin matematik sorularÄ±nÄ± anlayÄ±p doÄŸru ve kapsamlÄ± cevaplar Ã¼retebilmek iÃ§in tasarlanmÄ±ÅŸtÄ±r.

##  Sistem Mimarisi

### 1. **Temel BileÅŸenler**

#### ğŸ“š **Veri TabanÄ± (Knowledge Base)**
- **Matematik konularÄ±**: 1-8. sÄ±nÄ±f matematik mÃ¼fredatÄ±
- **DokÃ¼man formatÄ±**: JSON dosyalarÄ± (`mat1.json`, `mat2.json`, ..., `mat8.json`)
- **Ä°Ã§erik tÃ¼rÃ¼**: Konu anlatÄ±mlarÄ±, Ã¶rnek sorular, Ã§Ã¶zÃ¼mler
- **Toplam dokÃ¼man sayÄ±sÄ±**: 2,185 adet matematik iÃ§eriÄŸi

#### ğŸ” **Embedding Model**
- **Model**: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`
- **Boyut**: 384-dimensional vector space
- **Ã–zellik**: Ã‡ok dilli (multilingual) destek
- **KullanÄ±m**: DokÃ¼manlarÄ± ve sorgularÄ± vektÃ¶r uzayÄ±na dÃ¶nÃ¼ÅŸtÃ¼rme

#### ğŸ¤– **LLM (Large Language Model)**
- **Model**: `gemma-2-9b-it-tr-new` (TÃ¼rkÃ§e fine-tune edilmiÅŸ)
- **Boyut**: 9B parametre
- **Optimizasyon**: RTX 4090 iÃ§in Ã¶zel memory yÃ¶netimi
- **KullanÄ±m**: Cevap Ã¼retimi ve sorgu optimizasyonu

### 2. **RAG Pipeline AdÄ±mlarÄ±**

####  **1. Inquiry (Sorgu Alma)**
```python
inquiry = query  # KullanÄ±cÄ± sorgusu
```

####  **2. Pre-Process (Sorgu Optimizasyonu)**
```python
optimized_query = self.preprocess_query_with_llm(inquiry)
```
- LLM ile sorguyu matematik terimleri iÃ§in optimize etme
- Anahtar kelimeleri Ã§Ä±karma
- Sorgu netliÄŸini artÄ±rma

####  **3. Embed (VektÃ¶rleÅŸtirme)**
```python
query_embedding = self.advanced_rag.create_embedding_for_text(optimized_query)
```
- Sorguyu 384-dimensional vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rme
- Semantic similarity iÃ§in hazÄ±rlama

#### ğŸ” **4. Search (DokÃ¼man Arama)**
```python
retrieved_docs = self.advanced_rag.retrieve_relevant_documents(optimized_query, top_k=5)
```
- FAISS index kullanarak en ilgili 3-5 dokÃ¼manÄ± bulma
- Cosine similarity ile sÄ±ralama
- Embedding skoru hesaplama

####  **5. Filter (DokÃ¼man Filtreleme)**
```python
filtered_docs = self.filter_documents_with_llm(inquiry, retrieved_docs)
```
- LLM ile en uygun dokÃ¼manlarÄ± seÃ§me
- Kalite kontrolÃ¼
- Ä°lgisiz iÃ§erikleri eleme

#### **6. Build Prompt (Prompt OluÅŸturma)**
```python
context_prompt = self.build_rag_prompt(inquiry, filtered_docs)
```
- DokÃ¼manlarÄ± birleÅŸtirme
- Ã‡ocuklarÄ±n anlayabileceÄŸi formatta prompt hazÄ±rlama
- TÃ¼rkÃ§e matematik terminolojisi kullanma

#### âš¡ **7. Generate (Cevap Ãœretimi)**
```python
initial_response = self.generate_with_llm(context_prompt, max_length=300, temperature=0.7)
```
- LLM ile cevap Ã¼retme
- SÄ±caklÄ±k parametresi ile yaratÄ±cÄ±lÄ±k kontrolÃ¼
- Token limiti ile uzunluk kontrolÃ¼

#### ğŸ”„ **8. Self-Reflect (Kalite KontrolÃ¼)**
```python
final_response = self.self_reflect_and_improve(inquiry, initial_response, filtered_docs)
```
- Cevap kalitesini deÄŸerlendirme
- Gerekirse iyileÅŸtirme
- Embedding skorlarÄ± ile doÄŸrulama

### 3. **Ã–zel Ã–zellikler**

#### ğŸ“ **SÄ±nÄ±f BazlÄ± Ã–ÄŸrenme**
```python
self.class_topics = {
    "1": ["ğŸ“Š SayÄ±lar (1-100)", "â• Toplama Ä°ÅŸlemi", ...],
    "2": ["ï¿½ï¿½ SayÄ±lar (1-1000)", "âœ–ï¸ Ã‡arpma Ä°ÅŸlemi", ...],
    # ... 8. sÄ±nÄ±fa kadar
}
```

#### ğŸ§  **Memory Management**
- **KullanÄ±cÄ± mesajlarÄ±**: Son 7 mesaj
- **Bot mesajlarÄ±**: Son 7 cevap
- **KonuÅŸma geÃ§miÅŸi**: Context iÃ§in kullanÄ±m
- **Memory temizleme**: Her 3 mesajda bir GPU memory temizliÄŸi

#### âš¡ **GPU OptimizasyonlarÄ±**
```python
# RTX 4090 iÃ§in Ã¶zel ayarlar
torch.cuda.set_per_process_memory_fraction(0.85)  # GPU'nun %85'i
torch.cuda.empty_cache()  # Memory temizleme
max_memory={0: "4GB"}  # Memory limiti
```

### 4. **Sistem DosyalarÄ±**

#### **Core Files**
- **ğŸ§  EÄŸitilmiÅŸ model ve index dosyalarÄ± Linki**: [AdvancedRagSystemFiles Dataset](https://mega.nz/folder/5Jw1xR6Y#ZjmVueMOEhEjlhJ86hB6xQ)
- `advanced_rag.py`: Ana RAG sistemi
- `advanced_rag_chat_fixed.py`: Chatbot implementasyonu
- `advanced_rag_system/`: EÄŸitilmiÅŸ model ve index dosyalarÄ±

#### **Data Files**
- **ğŸ“Š Veri Seti Linki**: [AdvancedRagMatQuestions Dataset](https://huggingface.co/datasets/yagiz1323/AdvancedRagMatQuestions/tree/main)
- `mat1.json` - `mat8.json`: SÄ±nÄ±f bazlÄ± matematik iÃ§erikleri
- `mat1konu.json` - `mat8konu.json`: Konu anlatÄ±mlarÄ±
- `mat8_lgs.json`: LGS hazÄ±rlÄ±k iÃ§erikleri

#### **Web Interface**
- `app.py`: Flask web uygulamasÄ±
- `templates/`: HTML ÅŸablonlarÄ±
- `static/`: CSS, JS, ses dosyalarÄ±

### 5. **Performans Ã–zellikleri**

#### **HÄ±z OptimizasyonlarÄ±**
- **FAISS Index**: HÄ±zlÄ± dokÃ¼man arama
- **GPU Acceleration**: CUDA ile hÄ±zlandÄ±rma
- **Memory Management**: Agresif memory yÃ¶netimi
- **Batch Processing**: Toplu iÅŸlem desteÄŸi

#### ğŸ¯ **Kalite KontrolÃ¼**
- **Embedding SkorlarÄ±**: Semantic similarity kontrolÃ¼
- **Self-Reflection**: LLM ile kalite deÄŸerlendirmesi
- **Document Filtering**: Ä°lgisiz iÃ§erik eleme
- **Response Validation**: Cevap doÄŸrulama

### 6. **KullanÄ±m SenaryolarÄ±**

#### **Konu AnlatÄ±mÄ±**
```
KullanÄ±cÄ±: "Kesirlerde toplama nasÄ±l yapÄ±lÄ±r?"
Bot: [RAG sistemi ile kesir toplama konusunu aÃ§Ä±klar]
```

#### ğŸ§® **Soru Ã‡Ã¶zÃ¼mÃ¼**
```
KullanÄ±cÄ±: "2/3 + 1/4 = ?"
Bot: [AdÄ±m adÄ±m Ã§Ã¶zÃ¼mÃ¼ gÃ¶sterir]
```

#### ğŸ“ **SÄ±nÄ±f Seviyesi Belirleme**
```
KullanÄ±cÄ±: "Ben 3. sÄ±nÄ±fa gidiyorum"
Bot: [3. sÄ±nÄ±f konularÄ±nÄ± listeler]
```

### 7. **Teknik Detaylar**

####  **Model KonfigÃ¼rasyonu**
```python
# Embedding Model
model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
embedding_dimension = 384

# LLM Model
model_path = "./gemma-2-9b-it-tr-new"
max_memory = "4GB"
temperature = 0.7
max_length = 300
```

#### ğŸ“Š **Veri Ä°statistikleri**
- **Toplam dokÃ¼man**: 2,185 adet
- **SÄ±nÄ±f bazlÄ± daÄŸÄ±lÄ±m**: 1-8. sÄ±nÄ±f
- **Embedding boyutu**: 384-dimensional
- **FAISS index boyutu**: 3.2MB
- **Model boyutu**: 449MB

Bu sistem, TÃ¼rkÃ§e matematik eÄŸitimi iÃ§in Ã¶zel olarak tasarlanmÄ±ÅŸ, geliÅŸmiÅŸ bir RAG pipeline'Ä±dÄ±r. Ã–ÄŸrencilerin matematik sorularÄ±nÄ± anlayÄ±p doÄŸru ve kapsamlÄ± cevaplar Ã¼retebilmek iÃ§in optimize edilmiÅŸtir.
ğŸ® OyunlaÅŸtÄ±rÄ±lmÄ±ÅŸ Matematik Deneyimi
- Proje, sadece konu anlatÄ±mÄ± ve sohbet ile sÄ±nÄ±rlÄ± kalmaz; aynÄ± zamanda etkileÅŸimli bir matematik oyunu da sunar.

- KullanÄ±cÄ±ya ekranda sorular gelir, doÄŸru yanÄ±t verdikÃ§e zorluk seviyesi artar.
- Cevaplar farklÄ± lokasyonlarda yer alÄ±r; hÄ±z ve dikkat Ã¶nemlidir.
- DoÄŸru yanÄ±tlarla puan kazanÄ±lÄ±r, zor sorular daha fazla puan kazandÄ±rÄ±r.
- Arka planda Ã§alan mÃ¼zikler ve ses efektleri, tamamen AI ile Ã¼retilmiÅŸtir.

Bu sayede Ã¶ÄŸrenciler, eÄŸlenerek Ã¶ÄŸrenme deneyimi yaÅŸar.

ğŸ“– EtkileÅŸimli Hikaye Ãœretimi
- Projede yer alan AI destekli hikaye oluÅŸturma modÃ¼lÃ¼, kullanÄ±cÄ±nÄ±n yaratÄ±cÄ±lÄ±ÄŸÄ±nÄ± teÅŸvik eden interaktif bir yapÄ±ya sahiptir.
- KullanÄ±cÄ±, kendi hikaye baÅŸlangÄ±cÄ±nÄ± yazabilir veya sistemin sunduÄŸu rastgele 2 baÅŸlangÄ±Ã§tan birini seÃ§ebilir.
- Hikaye, 10 adÄ±mdan oluÅŸur. Her adÄ±mda kullanÄ±cÄ±ya 2 farklÄ± seÃ§enek sunulur ve seÃ§imlere gÃ¶re hikaye yÃ¶nlenir.
- Son adÄ±mda, yapay zekÃ¢ tarafÄ±ndan oluÅŸturulmuÅŸ 2 alternatif son gÃ¶sterilir.
- Tamamlanan hikaye:
- Sesli olarak dinlenebilir (TTS teknolojisiyle)
- PDF formatÄ±nda indirilebilir
- Hikaye Ã¼retimi sÃ¼recinde, metin oluÅŸturmak iÃ§in Gemini API kullanÄ±lmÄ±ÅŸtÄ±r.

Bu sistem, Ã¶ÄŸrencilere hem okuma-yazma becerisi hem de karar verme pratiÄŸi kazandÄ±rmayÄ± amaÃ§lar.


## ğŸ“‚ Proje YapÄ±sÄ± Ã–zeti

| Dosya/KlasÃ¶r | AÃ§Ä±klama |
|--------------|----------|
| `train_qlora_gemma_final_aggressive.py` | Gemma-2â€‘9Bâ€‘ITâ€‘TR modeli iÃ§in agresif parametrelerle LoRA Ã¼zerinden fineâ€‘tuning scripti |
| `test_qlora_final.py` | EÄŸitilmiÅŸ modelin soru-cevap yeteneklerini test eden betik |
| `advanced_rag_fixed.py`, `advanced_rag.py` | Embedding â€” Retriever â€” Response Generation hattÄ±nÄ± iÃ§eren RAG pipeline |
| `advanced_rag_chat_fixed.py` | RAG chatbot versiyonu; kullanÄ±cÄ± mesajÄ± alÄ±p cevap Ã¼retir |
| `app.py`, `app4.py` | Flask tabanlÄ± sohbet uygulama arayÃ¼zÃ¼ |
| `requirements_qlora.txt` | Model eÄŸitimi ve inference iÃ§in gerekli kÃ¼tÃ¼phaneler |
| `start_*.bat` | Windowsâ€™ta eÄŸitim ve test komut dosyalarÄ± |
| `templates/`, `static/` | Web uygulamasÄ± Ã¶n yÃ¼z bileÅŸenleri (HTML, CSS, JS) |
| `README_QLORA.md` | QLoRA Ã¶zel konfigÃ¼rasyonlarÄ±nÄ±n detaylarÄ± |

---
